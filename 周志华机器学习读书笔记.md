## **第二章** 模型评估与选择

* ​





## 第三章 线性模型

* 广义线性模型：$y = g^{-1}(w^Tx+b)$，其中函数$g$称为联系函数（link function）；

* 对数几率回归：使用Sigmoid函数作为联系函数进行映射，Sigmoid函数为$g = \frac{1}{1+e^{-x}}$；

  对数几率回归函数变换之后变成 $\ln(\frac{y}{1-y})=w^Tx+b$，其中经过变换$p(y=1|x) = \frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}$，$p(y=0|x) = \frac{1}{1+e^{w^Tx+b}}$，使用极大似然方法可以得到相关参数，

* LDA问题：

* 多分类问题:

* 类别不平衡的处理：

  * 再缩放(rescaling)
  * 欠采样：减少样本数较多的类别的样本，以平衡正负样本，典型算法EasyEnsemble算法
  * 过采样：增加样本数较少的类别的样本（并非重复采样），以平衡正负样本，典型算法SMOTE算法
  * 阈值移动：处理最后概率是使用样本比例进行缩放

## 第四章 决策树







## 第五章 神经网络



## 第六章 支持向量机

## 第七章 贝叶斯分类器

## 第八章 集成学习

* 集成学习：Ensemble Learning，通过结合多个学习器完成学习任务，亦称多分类器系统。
* 按照个体学习器分类：
  * 同质，个体学习器相同，单个学习器称为基学习器；
  * 异质，个体学习器不同，单个学习器称为组件/个体学习器；
* 按照集成学习器的生成方式分类：
  * 串行：个体学习器之间有强依赖关系，必须穿行生成序列化方法，代表
    * Boosting，Adaboost
    * GBDT，Xgboost
  * 并行：个体学习器不存在依赖关系，可并行训练，计算，代表有
    * Bagging
    * 随机森林
* 集成学习器要求：
  * 准确度：个体学习器需要具备一定的准确度；
  * 多样性：学习器之间具备一定的差异性；
  * 两者联系：相矛盾，准确度上升后，要想提升多样性，就会牺牲准确度。













